Week7(2/3)
min hash, 거대모델을 활용해서 유사도 분석 찾아봐서 실습
유사도 평균 보다 분포도로 표현해보기
딥러닝 모델로 사람을 대체하는 것이 아닌 -> 사람 + 딥러닝 모델 프레임으로 가야 반발심이 덜함

랜덤포레스트?
XAI 같이 결과 이우에 대해 설명이 가능 한 것 말고도,
학습이 잘 됐는지 알아보는 접근방법도 있음.(ex. dataset을 잘못 만든 경우)
-> top feature를 가지고 dicision tree를 만들어서 유저가 학습이 의도대로 되었는지 보기 좋게 해주는 방법
TrusteeML : https://github.com/TrusteeML/trustee

자카드 유사도
- 지난주 20개의 표본만으로 자카드 유사도의 평균
--> 133개의 전체 SPAM DATA를 가지고, 자카드 유사도의 평균 뿐 아니라 분포도를 통해 어떤 특징이 있는지
확인

BERT 모델 이용한 유사도 측정
(Ko-Sentence-BERT-SKTBERT)
https://github.com/BM-K/KoSentenceBERT-SKT
SKT KoBERT를 사용하여 SentenceBERT 학습

STS 단일 데이터를 이용한 Fine-tuning
https://colab.research.google.com/drive/1uGHdcpIslcegcfmxKt0q4TTP9kmIuIwX?authuser=1
위의 링크에서 제시하는 예제 실행
colab을 사용하는대 SPAM data를 올려도 되나요???


기존의 BERT로는 large-scale의 유사도 비교, 클러스터링, 정보 검색 등에 많은 시간 비용이 들어간다.
Sentence-BERT(SBERT)는 BERT의 출력에 풀링 연산을 추가한 모델
풀링 방법은 [CLS] 토큰의 결과를 사용하는 방법, 모든 출력 벡터를 평균내어 사용, 출력 벡터의 max-over-time을 계산해 사용하는 방법
기본적으로 SBERT는 평균 풀링을 사용하며, 평균 풀링으로 문장 표현을 얻으면 이 표현은 본질적으로 모든 단어의 의미를 갖는다. 반면 최대 풀링으로 문장 표현을 얻을 경우 문장 표현은 본질적으로 중요한 단어의 의미를 갖는다.
(Max-over-time pooling: 문장의 길이가 다 다르면 문장마다의 feature map 개수가 달라지는데, 모든 문장마다 하나의 값을 갖도록 feature map 벡터 중 가장 큰 값 하나만 사용하는 것)
