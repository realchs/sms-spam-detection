인턴쉽
12월14일까지 제안 주제 임신영 교수님께 제출
12월 19일이후부터 일주일에 하루 진행상황 보고 미팅을 하는 방식
SKT 최현상 박사님

NER하셨었고, SPAM 탐지!(clues in Tweets)
sns, 이메일, SMS 스팸에 초점!!
이미 문자스팸 거르는 서비스를 받고 있음.
이미 있는 기술이 옛날기술을 많이 사용하고 있어서 -> 성능이 떨어짐
스팸감지기술이 오래됨(랜덤 포레스트) -> 스팸이라고 찾았는데 왜 스팸이라고 찾았는지 모름(스팸이 아닐 수도 있음) -> 소송걸림 -> 담당자들도 왜 스팸처리 됬는지 알 수 가 없음 -> 앞으로 만들거는 설명이 가능해야 함.
정상데이터를 쓸 수 없음: (고객개인데이터라서) -> 스팸으로 차단된 데이터만 사용할 수 있음 -> 데이터를 어떻게 모을 건지가 과제임 -> 위의 논문에 나와있는 트위터에서 데이터를 얻을 수 있음.(트위터 크롤링 연습)
데이터만 얻는다고 심플하진 않음. -> LSH 같은 "해싱?"같은 전처리 기술에 대한 아이디어도 필요
(케글에 머신러닝 이용한 디택팅 SMS 스팸) 등등 <- 연구 배경지식 관련 자료 공유해주신다고 함.
스팸쪽, 나머지

week 1
스팸데이터 -> 제공 가능 해 보임
케글
스팸 vs 햄
스팸 데이터는 사용 가능해보임 하지만 햄 데이터는 함부로 못 건드려서 데이터를 어떻게 구할지 연구
개인 핸드폰의 문자메세지를 텍스트 추출 가능(개인정보 알아서 거르기)
4명 데이터 모아서 생성모델(어려움)
1. 오버샘플링도 가능해 보임
2. 트위터 데이터 수집
3. AIhub 데이터셋 이용가능한 자료 찾아보기
4. 영문데이터 셋 -> 번역기


SPAM + HAM 데이터 분석

kaggle -> feature emgineering -> boosting기법
거대모델 bert (트랜스포머)-> fine tuning

관련 논문 : 소셜 네트워크 기반 대량의 SMS 스팸 데이터 재구성 기법

Week2
전처리
microsoft presidio -> 카톡 링크
spacy? -> 모델에 가면 데이터 다운 가능
pip로 다운 가능
한글은 정확도가 낮을 수도
최미소님에게 방법 제시해주신대로 전달드리기

Week3 (1/6)
- 스팸데이터 특징들을 분석해오기
--> 스팸데이터는 처리 후 데이터는 삭제

- SMS data 개인정보(주민번호, 잔액? 등등)만 지우고 보내기

Week4 (1/13)
- 전처리 영어나 특수문자로 지우는 건X
정규표현으로 진행

- 스팸 데이터 분석
-> 케글 보면서 판다스 이용해서 분석 진행
-> 다양한 방법으로 분석 진행 

- 본인 문자메세지를 카테고라이징
개인간의 대화는 제외

Week6(1/27)
lsh, minhash
probalistic data structure
다른 이득을 얻기 위해서 정확도를 살짝 포기한다.
어떤 결과를 러프하게 알기 위한 경우 많이 쓰인다.해시써야 좋음
ip버전 사이즈?
전체개수 만큼 해시 사이즈가 필요
유사한것을 측정하는 것은 많이 쓰이고 중요함. -> 쉽지 않다.
해싱 진행? -> 정확한게 아니라 데이터가 비슷하면 비슷한 결과 값을 내는 해싱이 있다.
-> locality sensitive hashing(LSH) :: reformer
minhash : 교집합/합집합
스팸데이터와 내데이터를 가지고 유사도 측정을 해보는 실험을 진행
트랜스포머 BERT 유투브나 구글을 통해서 스터디 및 예제실습 진행

Week7(2/3)
min hash, 거대모델을 활용해서 유사도 분석 찾아봐서 실습
유사도 평균 보다 분포도로 표현해보기
딥러닝 모델로 사람을 대체하는 것이 아닌 -> 사람 + 딥러닝 모델 프레임으로 가야 반발심이 덜함

랜덤포레스트?
XAI 같이 결과 이우에 대해 설명이 가능 한 것 말고도,
학습이 잘 됐는지 알아보는 접근방법도 있음.(ex. dataset을 잘못 만든 경우)
-> top feature를 가지고 dicision tree를 만들어서 유저가 학습이 의도대로 되었는지 보기 좋게 해주는 방법
TrusteeML : https://github.com/TrusteeML/trustee

